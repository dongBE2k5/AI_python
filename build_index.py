import os
import faiss
import torch
from llama_index.core import (
    SimpleDirectoryReader,
    VectorStoreIndex,
    StorageContext,
    Settings,
)
from llama_index.core.node_parser import SemanticSplitterNodeParser
from llama_index.vector_stores.faiss import FaissVectorStore
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

# --- 1. Cáº¤U HÃŒNH ÄÆ¯á»œNG DáºªN ---
DATA_DIR = "data"
STORAGE_DIR = "storage"
os.makedirs(STORAGE_DIR, exist_ok=True)

# --- 2. Cáº¤U HÃŒNH EMBEDDING MODEL (LOCAL) ---
# ChÃºng ta dÃ¹ng MiniLM-L6-v2 (384 chiá»u) - Nháº¹ vÃ  hiá»‡u quáº£ cho tiáº¿ng Viá»‡t/Anh
print("â³ Äang táº£i embedding model...")
embed_model = HuggingFaceEmbedding(
    model_name="sentence-transformers/all-MiniLM-L12-v2",
    device="cuda" if torch.cuda.is_available() else "cpu" # DÃ¹ng GPU náº¿u cÃ³
)
Settings.embed_model = embed_model

# --- 3. Cáº¤U HÃŒNH SEMANTIC CHUNKING ---
# Thay vÃ¬ cáº¯t theo Ä‘á»™ dÃ i, chÃºng ta cáº¯t khi Ã½ nghÄ©a thay Ä‘á»•i
print("ğŸ§  Äang khá»Ÿi táº¡o Semantic Splitter...")
splitter = SemanticSplitterNodeParser(
    buffer_size=1, 
    breakpoint_percentile_threshold=95, 
    embed_model=embed_model
)

# --- 4. Äá»ŒC TÃ€I LIá»†U ---
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)
    print(f"âš ï¸ ThÆ° má»¥c '{DATA_DIR}' trá»‘ng. HÃ£y bá» file PDF/Docx vÃ o Ä‘Ã³ rá»“i cháº¡y láº¡i.")
    exit()

print(f"ğŸ“„ Äang Ä‘á»c tÃ i liá»‡u tá»« {DATA_DIR}...")
documents = SimpleDirectoryReader(DATA_DIR, recursive=True).load_data()

# --- 5. CHUYá»‚N Äá»”I SANG NODES (Cáº®T THEO NGá»® NGHÄ¨A) ---
print("âœ‚ï¸ Äang phÃ¢n tÃ­ch vÃ  cáº¯t nhá» tÃ i liá»‡u theo ngá»¯ nghÄ©a (cÃ³ thá»ƒ máº¥t Ã­t phÃºt)...")
nodes = splitter.get_nodes_from_documents(documents)
print(f"âœ… ÄÃ£ táº¡o {len(nodes)} chunks (nodes) cháº¥t lÆ°á»£ng.")

# --- 6. Cáº¤U HÃŒNH KHO VECTOR FAISS ---
dimension = 384 # Khá»›p vá»›i MiniLM-L6-v2
faiss_index = faiss.IndexFlatL2(dimension)
vector_store = FaissVectorStore(faiss_index=faiss_index)
storage_context = StorageContext.from_defaults(vector_store=vector_store)

# --- 7. XÃ‚Y Dá»°NG CHá»ˆ Má»¤C (INDEXING) ---
print("ğŸš€ Äang xÃ¢y dá»±ng Vector Index...")
index = VectorStoreIndex(
    nodes, 
    storage_context=storage_context, 
    show_progress=True
)

# --- 8. LÆ¯U TRá»® VÄ¨NH VIá»„N ---
print("ğŸ’¾ Äang lÆ°u trá»¯ dá»¯ liá»‡u xuá»‘ng á»• Ä‘Ä©a...")
# LÆ°u metadata (cÃ¡c file json)
index.storage_context.persist(persist_dir=STORAGE_DIR)

# LÆ°u file nhá»‹ phÃ¢n FAISS (Quan trá»ng Ä‘á»ƒ main.py Ä‘á»c Ä‘Æ°á»£c)
faiss.write_index(faiss_index, os.path.join(STORAGE_DIR, "faiss.index"))

print("\n" + "="*30)
print("âœ… THÃ€NH CÃ”NG: FAISS Index Ä‘Ã£ sáºµn sÃ ng!")
print(f"ğŸ“ Vá»‹ trÃ­ lÆ°u: {STORAGE_DIR}")
print("="*30)